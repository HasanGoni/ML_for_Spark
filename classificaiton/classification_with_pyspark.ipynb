{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.24:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classification_first</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f343c2771c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"classification_first\")\\\n",
    "        .getOrCreate()\n",
    "spark\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of preprocssing failed: Traceback (most recent call last):\n",
      "  File \"/home/hasan/anaconda3/envs/spark_env_new/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/hasan/anaconda3/envs/spark_env_new/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/hasan/anaconda3/envs/spark_env_new/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/hasan/anaconda3/envs/spark_env_new/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 976, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 906, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/hasan/Schreibtisch/projects/Udemy/Pyspark Essential for Data Sceintists/Spark_ML/ML_for_github/classificaiton/preprocssing.py\", line 185\n",
      "    print(f'{features_list}')\n",
      "    ^\n",
      "IndentationError: unexpected indent\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from preprocssing import preprocess_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing dataframe\n",
      " =====\n",
      "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
      "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
      "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
      "\n",
      "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
      "0   f  middle eastern      yes                  no          family member   \n",
      "1   m  White European      yes                  no          family member   \n",
      "\n",
      "  Class/ASD Traits   \n",
      "0                No  \n",
      "1               Yes  \n",
      "number of rows 1054\n",
      "removing nan from columns\n",
      "number of rows 1054\n",
      " printing dataframe schema \n",
      "\n",
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      "\n",
      "None\n",
      "This is a classification problem, showing distribution of dependent variable\n",
      "\n",
      " === printing distribution of output \n",
      " ====\n",
      "  Class/ASD Traits   count\n",
      "0                No    326\n",
      "1               Yes    728\n",
      "\n",
      " == independent variables are ['Case_No', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons', 'Qchat-10-Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test'] == \n",
      "\n",
      " extracting continuous and categorical variables \n",
      "\n",
      " ======  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test,cont_vars, cat_vars = preprocess_csv(\n",
    "    csv_file_name='Toddler Autism dataset July 2018.csv',\n",
    "    dependent_var='Class/ASD Traits ',\n",
    "    treat_outlier=True,\n",
    "    train_split=0.7,\n",
    "    test_split=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Case_No',\n",
       " 'A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'Age_Mons',\n",
       " 'Qchat-10-Score',\n",
       " 'Sex',\n",
       " 'Ethnicity',\n",
       " 'Jaundice',\n",
       " 'Family_mem_with_ASD',\n",
       " 'Who completed the test',\n",
       " 'Class/ASD Traits ',\n",
       " 'Who completed the test_num']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Case_No',\n",
       " 'A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'Age_Mons',\n",
       " 'Qchat-10-Score']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_num',\n",
       " 'Ethnicity_num',\n",
       " 'Jaundice_num',\n",
       " 'Family_mem_with_ASD_num',\n",
       " 'Who completed the test_num']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Case_No',\n",
       " 'A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'Age_Mons',\n",
       " 'Qchat-10-Score',\n",
       " 'Sex',\n",
       " 'Ethnicity',\n",
       " 'Jaundice',\n",
       " 'Family_mem_with_ASD',\n",
       " 'Who completed the test',\n",
       " 'Class/ASD Traits ',\n",
       " 'Who completed the test_num']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocssing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocssing.py\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"classification_first\")\\\n",
    "        .getOrCreate()\n",
    "spark\n",
    "    \n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import (IntegerType,\n",
    "                               FloatType,\n",
    "                               StringType)\n",
    "from pyspark.ml.feature import (StringIndexer,\n",
    "                                VectorAssembler,\n",
    "                                MinMaxScaler,\n",
    "                                StandardScaler)\n",
    "\n",
    "from pyspark.ml.classification import (RandomForestClassifier,\n",
    "                                       GBTClassifier)\n",
    "\n",
    "from pyspark.ml.evaluation import (BinaryClassificationEvaluator,\n",
    "                                   MulticlassClassificationEvaluator)\n",
    "\n",
    "from pyspark.ml.tuning import (CrossValidator,\n",
    "                               ParamGridBuilder)\n",
    "\n",
    "def convert_cat_type(\n",
    "    df,\n",
    "    col_name:str):\n",
    "\n",
    "    indexed = StringIndexer(\n",
    "        inputCol=col_name,\n",
    "        outputCol=f'{col_name}_num'\n",
    "    )\n",
    "    df_in = indexed.fit(df).transform(df)\n",
    "\n",
    "    return df_in\n",
    "\n",
    "\n",
    "\n",
    "def cont_cat_split(df, independent_vars):\n",
    "\n",
    "    cont_columns = []\n",
    "    cat_columns = []\n",
    "\n",
    "    for i in independent_vars:\n",
    "        if str(df.schema[i].dataType) == 'StringType':\n",
    "\n",
    "            new_column_name = f'{i}_num'\n",
    "            df = convert_cat_type(\n",
    "                df,\n",
    "                col_name=i)\n",
    "\n",
    "            cat_columns.append(new_column_name)\n",
    "        else:\n",
    "            cont_columns.append(i)\n",
    "\n",
    "    return df, cont_columns, cat_columns\n",
    "\n",
    "\n",
    "def percentile_from_continuous_var(\n",
    "    df,\n",
    "    continuous_columns):\n",
    "\n",
    "    d = { }\n",
    "\n",
    "    for i in continuous_columns:\n",
    "        d[i] = df.approxQuantile(i, [0.01, 0.99], 0.01)\n",
    "\n",
    "    return d\n",
    "\n",
    "def treat_outliers(\n",
    "    indexed,\n",
    "    numeric_inputs,\n",
    "    d):\n",
    "\n",
    "    for col in numeric_inputs:\n",
    "        skew = indexed.agg(\n",
    "            skewness(\n",
    "                indexed[col])\n",
    "        ).collect()\n",
    "        skew = skew[0][0]\n",
    "        if skew > 1:\n",
    "            indexed = indexed.withColumn(\n",
    "                col,\n",
    "                log(when(df[col] < d[col][0],d[col][0])\\\n",
    "                    .when(indexed[col] >d[col][1], d[col][1])\\\n",
    "                    .otherwise(indexed[col]) +1).alias(col)\n",
    "            )\n",
    "\n",
    "            print(f'{col} has been treated for positive right skewness')\n",
    "        elif skew < -1:\n",
    "            indexed = indexed.withColumn(\n",
    "                col,\n",
    "                exp(\n",
    "                    when(df[col] < d[col][0], d[col][0])\\\n",
    "                   .when(df[col] > d[col][1], d[col][1])\\\n",
    "                   .otherwise(df[col])\n",
    "                   ).alias(col)\n",
    "                   )\n",
    "            print(f'{col} has been treated for negative (left) skewness')\n",
    "\n",
    "    return indexed\n",
    "\n",
    "\n",
    "def preprocess_csv(\n",
    "    csv_file_name:str,\n",
    "    dependent_var:str,\n",
    "    treat_outlier=False,\n",
    "    train_split=0.7,\n",
    "    test_split=0.3):\n",
    "\n",
    "    df = spark.read.csv(\n",
    "        csv_file_name,\n",
    "        header=True,\n",
    "        inferSchema=True)\n",
    "    \n",
    "    print('printing dataframe\\n =====')\n",
    "    print(df.limit(2).toPandas())\n",
    "\n",
    "    print(f'number of rows {df.count()}')\n",
    "\n",
    "    print(f'removing nan from columns')\n",
    "    df = df.na.drop()\n",
    "    print(f'number of rows {df.count()}')\n",
    "\n",
    "    print(f' printing dataframe schema \\n')\n",
    "    print(df.printSchema())\n",
    "\n",
    "    print(\n",
    "        'This is a classification problem, showing distribution of dependent variable\\n')\n",
    "    \n",
    "    dependent_var_distribution = df.groupBy(dependent_var).count().toPandas()\n",
    "\n",
    "    print(f' === printing distribution of output \\n ====')\n",
    "\n",
    "    print(dependent_var_distribution)\n",
    "\n",
    "    dependent_var_distribution.plot.barh()\n",
    "\n",
    "    independent_vars = df.columns\n",
    "    independent_vars.remove(dependent_var)\n",
    "\n",
    "    print(f'\\n == independent variables are {independent_vars} == \\n')\n",
    "\n",
    "\n",
    "    print(f' extracting continuous and categorical variables \\n')\n",
    "\n",
    "    print(f' ======  ')\n",
    "\n",
    "    df, cont_vars, cat_vars = cont_cat_split(\n",
    "        df,independent_vars)\n",
    "\n",
    "    df_indexed = df\n",
    "\n",
    "    print(df_indexed.columns)\n",
    "\n",
    "    print(f' continuous variables are ===  {cont_vars} === \\n categorical variables == {cat_vars}')\n",
    "\n",
    "    print(f' percentile of continuous columns extracting in a dictionary')\n",
    "\n",
    "    dict_ = percentile_from_continuous_var(\n",
    "    df_indexed,\n",
    "        cont_vars)\n",
    "\n",
    "    if treat_outlier:\n",
    "\n",
    "        print(' Treating outliers === \\n')\n",
    "\n",
    "        df_indexed = treat_outliers(\n",
    "            df_indexed,\n",
    "            cont_vars,\n",
    "                dict_)\n",
    "\n",
    "    else: print(f'== outliers is not treated === ')\n",
    "\n",
    "    features_list = cont_vars + cat_vars\n",
    "\n",
    "    print(f' =====so now columns are \\n ===========')\n",
    "\n",
    "    print(df_indexed.columns)\n",
    "\n",
    "    print(f'\\n')\n",
    "    print(f' ===================== features list ============\\n')\n",
    "    print(f'{features_list}')\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=features_list,\n",
    "        outputCol='features'\n",
    "    )\n",
    "    df_new = assembler.transform(\n",
    "            df_indexed).select('features', 'label')\n",
    "\n",
    "    min_=0\n",
    "    max_=1000\n",
    "\n",
    "    print(f' scaling features to Minmax\\n minimum is = {min_} and maximum is  { max_}')\n",
    "    scaler = MinMaxScaler(\n",
    "        inputCol='features',\n",
    "        outputCol='scaledFeatures',\n",
    "        min=min_,\n",
    "        max=max_\n",
    "        )\n",
    "\n",
    "    scaled_data = scaler.fit(df_new).transform(df_new)\n",
    "\n",
    "    final_data = scaled_data.select(\n",
    "        'label','scaledFeatures'\n",
    "        )\n",
    "\n",
    "    print(final_data.show(5))\n",
    "\n",
    "    # Rename to default value\n",
    "    final_data = final_data.withColumnRenamed(\n",
    "        'scaledFeatures',\n",
    "        'features'\n",
    "        )\n",
    "\n",
    "    print(f' printing again the reamed version of data\\n')\n",
    "    print(final_data.show(5))\n",
    "\n",
    "    print('splitting the data to test and training set')\n",
    "\n",
    "    df_train, df_test = final_data.randomSplit(\n",
    "        [train_split, test_split]\n",
    "    )\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+----------------------+-----------------+\n",
      "|Case_No| A1| A2| A3| A4| A5| A6| A7| A8| A9|A10|Age_Mons|Qchat-10-Score|Sex|     Ethnicity|Jaundice|Family_mem_with_ASD|Who completed the test|Class/ASD Traits |\n",
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+----------------------+-----------------+\n",
      "|      1|  0|  0|  0|  0|  0|  0|  1|  1|  0|  1|      28|             3|  f|middle eastern|     yes|                 no|         family member|               No|\n",
      "|      2|  1|  1|  0|  0|  0|  1|  1|  0|  0|  0|      36|             4|  m|White European|     yes|                 no|         family member|              Yes|\n",
      "|      3|  1|  0|  0|  0|  0|  0|  1|  1|  0|  1|      36|             4|  m|middle eastern|     yes|                 no|         family member|              Yes|\n",
      "|      4|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|      24|            10|  m|      Hispanic|      no|                 no|         family member|              Yes|\n",
      "|      5|  1|  1|  0|  1|  1|  1|  1|  1|  1|  1|      20|             9|  f|White European|      no|                yes|         family member|              Yes|\n",
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+----------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    'Toddler Autism dataset July 2018.csv',\n",
    "    header=True,\n",
    "    inferSchema=True)\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame row number before na removal 1054\n",
      "Data Frame row number after na removal 1054\n"
     ]
    }
   ],
   "source": [
    "print(f'Data Frame row number before na removal {df.count()}')\n",
    "df = df.na.drop()\n",
    "\n",
    "print(f'Data Frame row number after na removal {df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class/ASD Traits   count\n",
       "0                No    326\n",
       "1               Yes    728"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_variable = 'Class/ASD Traits '\n",
    "count_df = df.groupBy(dependent_variable).count().toPandas()\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_df.plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variable = df.columns\n",
    "independent_variable.remove(dependent_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class/ASD Traits '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+----------------------+-----------------+-----+\n",
      "|Case_No| A1| A2| A3| A4| A5| A6| A7| A8| A9|A10|Age_Mons|Qchat-10-Score|Sex|     Ethnicity|Jaundice|Family_mem_with_ASD|Who completed the test|Class/ASD Traits |label|\n",
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+----------------------+-----------------+-----+\n",
      "|      1|  0|  0|  0|  0|  0|  0|  1|  1|  0|  1|      28|             3|  f|middle eastern|     yes|                 no|         family member|               No|  1.0|\n",
      "|      2|  1|  1|  0|  0|  0|  1|  1|  0|  0|  0|      36|             4|  m|White European|     yes|                 no|         family member|              Yes|  0.0|\n",
      "|      3|  1|  0|  0|  0|  0|  0|  1|  1|  0|  1|      36|             4|  m|middle eastern|     yes|                 no|         family member|              Yes|  0.0|\n",
      "|      4|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|      24|            10|  m|      Hispanic|      no|                 no|         family member|              Yes|  0.0|\n",
      "|      5|  1|  1|  0|  1|  1|  1|  1|  1|  1|  1|      20|             9|  f|White European|      no|                yes|         family member|              Yes|  0.0|\n",
      "+-------+---+---+---+---+---+---+---+---+---+---+--------+--------------+---+--------------+--------+-------------------+----------------------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(\n",
    "    inputCol=dependent_variable,\n",
    "    outputCol='label'\n",
    ")\n",
    "df = indexer.fit(df).transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_cat_split(df):\n",
    "\n",
    "    cont_columns = []\n",
    "    cat_columns = []\n",
    "\n",
    "    for col in independent_variable:\n",
    "        if str(df.schema[col].dataType) == 'StringType':\n",
    "            new_column_name = f'{col}_num'\n",
    "            indexer = StringIndexer(\n",
    "                inputCol=col,\n",
    "                outputCol=new_column_name)\n",
    "            df_indexed = indexer.fit(df).transform(df)\n",
    "            cat_columns.append(new_column_name)\n",
    "        else:\n",
    "            cont_columns.append(col)\n",
    "            df_indexed = df\n",
    "\n",
    "    return df_indexed, cont_columns, cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed, cont_columns, cat_columns = cont_cat_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- Who completed the test_num: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_indexed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Case_No',\n",
       " 'A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'Age_Mons',\n",
       " 'Qchat-10-Score']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex_num',\n",
       " 'Ethnicity_num',\n",
       " 'Jaundice_num',\n",
       " 'Family_mem_with_ASD_num',\n",
       " 'Who completed the test_num']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for i in cont_columns:\n",
    "    d[i] = df_indexed.approxQuantile(\n",
    "        i, [0.01, 0.99], 0.01\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cont_columns:\n",
    "    sken"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1123dae94279c660cf34f777dea29eda36172fe1a19971838176cb40ac3ccca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('spark_env_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
