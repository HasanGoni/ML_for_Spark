{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.24:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classifiction_first_notebook</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f00b870aa00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .appName('classifiction_first_notebook')\\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "\n",
       "  Class/ASD Traits   \n",
       "0                No  \n",
       "1               Yes  \n",
       "2               Yes  \n",
       "3               Yes  \n",
       "4               Yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Toddler Autism dataset July 2018.csv'\n",
    "df = spark.read.csv(path,\n",
    "                    inferSchema=True,\n",
    "                    header=True)\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|Class/ASD Traits |count|\n",
      "+-----------------+-----+\n",
      "|               No|  326|\n",
      "|              Yes|  728|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Class/ASD Traits \").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and outputs formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'Age_Mons',\n",
       " 'Qchat-10-Score',\n",
       " 'Sex',\n",
       " 'Ethnicity',\n",
       " 'Jaundice',\n",
       " 'Family_mem_with_ASD',\n",
       " 'Who completed the test']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_columns = df.columns[1:-1]\n",
    "output_column = 'Class/ASD Traits '\n",
    "input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output columns formatting\n",
    "renamed = df.withColumn('label_str', \n",
    "                        df[output_column].cast(StringType()))\n",
    "indexer = StringIndexer(\n",
    "                    inputCol='label_str', \n",
    "                    outputCol='label')\n",
    "indexed = indexer.fit(renamed).transform(renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|label|label_str|\n",
      "+-----+---------+\n",
      "|  1.0|       No|\n",
      "|  0.0|      Yes|\n",
      "|  0.0|      Yes|\n",
      "|  0.0|      Yes|\n",
      "|  0.0|      Yes|\n",
      "+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.select(['label', 'label_str']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input columns\n",
    "\n",
    "numeric_inputs = []\n",
    "string_inputs = []\n",
    "\n",
    "for column in input_columns:\n",
    "    if str(indexed.schema[column].dataType) == 'StringType':\n",
    "        indexer = StringIndexer(\n",
    "            inputCol=column,\n",
    "            outputCol=column + \"_num\"\n",
    "        )\n",
    "        indexed = indexer.fit(indexed).transform(\n",
    "            indexed\n",
    "        )\n",
    "        string_inputs.append(f\"{column}_num\")\n",
    "    else:\n",
    "        numeric_inputs.append(column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Case_No: integer (nullable = true)\n",
      " |-- A1: integer (nullable = true)\n",
      " |-- A2: integer (nullable = true)\n",
      " |-- A3: integer (nullable = true)\n",
      " |-- A4: integer (nullable = true)\n",
      " |-- A5: integer (nullable = true)\n",
      " |-- A6: integer (nullable = true)\n",
      " |-- A7: integer (nullable = true)\n",
      " |-- A8: integer (nullable = true)\n",
      " |-- A9: integer (nullable = true)\n",
      " |-- A10: integer (nullable = true)\n",
      " |-- Age_Mons: integer (nullable = true)\n",
      " |-- Qchat-10-Score: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Jaundice: string (nullable = true)\n",
      " |-- Family_mem_with_ASD: string (nullable = true)\n",
      " |-- Who completed the test: string (nullable = true)\n",
      " |-- Class/ASD Traits : string (nullable = true)\n",
      " |-- label_str: string (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- Sex_num: double (nullable = false)\n",
      " |-- Ethnicity_num: double (nullable = false)\n",
      " |-- Jaundice_num: double (nullable = false)\n",
      " |-- Family_mem_with_ASD_num: double (nullable = false)\n",
      " |-- Who completed the test_num: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for col in numeric_inputs:\n",
    "    d[col] = indexed.approxQuantile(\n",
    "        col, [0.01, 0.99], 0.25\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': [0.0, 1.0], 'A2': [0.0, 1.0], 'A3': [0.0, 1.0], 'A4': [0.0, 1.0], 'A5': [0.0, 1.0], 'A6': [0.0, 1.0], 'A7': [0.0, 1.0], 'A8': [0.0, 1.0], 'A9': [0.0, 1.0], 'A10': [0.0, 1.0], 'Age_Mons': [12.0, 36.0], 'Qchat-10-Score': [0.0, 10.0]}\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['A1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for skewness removal\n",
    "# if right skew then log +1\n",
    "# if left skew the exponential\n",
    "for col in numeric_inputs:\n",
    "    skew = indexed.agg(\n",
    "        skewness(\n",
    "            indexed[col])\n",
    "    ).collect()\n",
    "    skew = skew[0][0]\n",
    "    if skew > 1:\n",
    "        indexed = indexed.withColumn(\n",
    "            col,\n",
    "            log(when(df[col] < d[col][0],d[col][0])\\\n",
    "                .when(indexed[col] >d[col][1], d[col][1])\\\n",
    "                .otherwise(indexed[col]) +1).alias(col)\n",
    "        )\n",
    "\n",
    "        print(f'{col} has been treated for positive right skewness')\n",
    "    elif skew < -1:\n",
    "        indexed = indexed.withColumn(\n",
    "            col,\n",
    "            exp(\n",
    "                when(df[col] < d[col][0], d[col][0])\\\n",
    "               .when(df[col] > d[col][1], d[col][1])\\\n",
    "               .otherwise(df[col])\n",
    "               ).alias(col)\n",
    "               )\n",
    "        print(f'{col} has been treated for negative (left) skewness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score\n",
       "0   0   0   0   0   0   0   0   0   0    0        12               0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case there is negative values then\n",
    "# Naive Bayes algorithm can not be implemented\n",
    "# therefore searching for negative value\n",
    "\n",
    "# Calculate minimums for all columns\n",
    "minimums = df.select(\n",
    "    [ min(c).alias(c) for c in df.columns if c in numeric_inputs]\n",
    "                   )\n",
    "minimums.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|mins                                 |\n",
      "+-------------------------------------+\n",
      "|[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0]|\n",
      "+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_array = minimums.select(\n",
    "    array(numeric_inputs).alias('mins')\n",
    ")\n",
    "min_array.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_minimum = min_array.select(\n",
    "    array_min(min_array.mins)\n",
    ").collect()\n",
    "df_minimum[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'Age_Mons',\n",
       " 'Qchat-10-Score',\n",
       " 'Sex_num',\n",
       " 'Ethnicity_num',\n",
       " 'Jaundice_num',\n",
       " 'Family_mem_with_ASD_num',\n",
       " 'Who completed the test_num']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now create your final features list\n",
    "\n",
    "features_list = numeric_inputs + string_inputs\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=features_list,\n",
    "    outputCol='features'\n",
    ")\n",
    "output = assembler.transform(\n",
    "    indexed\n",
    ").select('features', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+-----+\n",
      "|features                                                               |label|\n",
      "+-----------------------------------------------------------------------+-----+\n",
      "|(17,[6,7,9,10,11,12,13,14],[1.0,1.0,1.0,28.0,3.0,1.0,2.0,1.0])         |1.0  |\n",
      "|(17,[0,1,5,6,10,11,14],[1.0,1.0,1.0,1.0,36.0,4.0,1.0])                 |0.0  |\n",
      "|(17,[0,6,7,9,10,11,13,14],[1.0,1.0,1.0,1.0,36.0,4.0,2.0,1.0])          |0.0  |\n",
      "|[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,24.0,10.0,0.0,5.0,0.0,0.0,0.0]|0.0  |\n",
      "|[1.0,1.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,20.0,9.0,1.0,0.0,0.0,1.0,0.0] |0.0  |\n",
      "+-----------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/06 19:34:02 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "output.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled to range:     (0.0, 1000.0)\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                              |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0  |(17,[6,7,9,10,11,12,13,14],[1000.0,1000.0,1000.0,666.6666666666666,300.0,1000.0,200.0,1000.0])                        |\n",
      "|0.0  |(17,[0,1,5,6,10,11,14],[1000.0,1000.0,1000.0,1000.0,1000.0,400.0,1000.0])                                             |\n",
      "|0.0  |(17,[0,6,7,9,10,11,13,14],[1000.0,1000.0,1000.0,1000.0,1000.0,400.0,200.0,1000.0])                                    |\n",
      "|0.0  |[1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,500.0,1000.0,0.0,500.0,0.0,0.0,0.0]            |\n",
      "|0.0  |[1000.0,1000.0,0.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,333.3333333333333,900.0,1000.0,0.0,0.0,1000.0,0.0]|\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(\n",
    "    inputCol='features',\n",
    "    outputCol='scaledFeatures',\n",
    "    min=0,\n",
    "    max=1000\n",
    ")\n",
    "\n",
    "print(f\"Features scaled to range:\\\n",
    "     {scaler.getMin(), scaler.getMax()}\")\n",
    "\n",
    "scalerModel = scaler.fit(output)\n",
    "\n",
    "scaled_data = scalerModel.transform(\n",
    "    output\n",
    ")\n",
    "final_data = scaled_data.select(\n",
    "    'label','scaledFeatures'\n",
    ")\n",
    "\n",
    "# Rename to default value\n",
    "final_data = final_data.withColumnRenamed(\n",
    "    'scaledFeatures',\n",
    "    'features'\n",
    ")\n",
    "final_data.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Test and Training datasets\n",
    "\n",
    "train, test = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import (CrossValidator,\n",
    "                               ParamGridBuilder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin_evaluator = BinaryClassificationEvaluator(\n",
    "    rawPredictionCol='prediction'\n",
    ")\n",
    "\n",
    "Mc_evaluator = MulticlassClassificationEvaluator(\n",
    "    metricName='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/06 19:43:13 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/02/06 19:43:13 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "predictionAndLabel=fitModel.transform(\n",
    "    test\n",
    ")\n",
    "auc = Bin_evaluator.evaluate(\n",
    "    predictionAndLabel)\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "# can be done with multiclass Classification\n",
    "predictions = fitModel.transform(\n",
    "    test\n",
    ")\n",
    "accuracy = (Mc_evaluator.evaluate(\n",
    "    predictions))*100\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [51.25340384465132]\n",
      "Coefficients: DenseMatrix([[-0.01141508, -0.0102881 , -0.01042605, -0.01207538, -0.00996857,\n",
      "              -0.01165182, -0.010967  , -0.00991785, -0.01118944, -0.01121953,\n",
      "              -0.00199482, -0.0302907 , -0.00026916, -0.00278132, -0.00057139,\n",
      "              -0.00028023, -0.00382372]])\n"
     ]
    }
   ],
   "source": [
    "# First which algorithm to use\n",
    "classifier = LogisticRegression()\n",
    "paramGrid =(\n",
    "    ParamGridBuilder().addGrid(\n",
    "        classifier.maxIter,\n",
    "        [10, 15, 20]\n",
    "    ).build()) \n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimator=classifier,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=Mc_evaluator,\n",
    "    numFolds=2\n",
    ")\n",
    "\n",
    "fitModel = crossval.fit(\n",
    "    train\n",
    ")\n",
    "BestModel = fitModel.bestModel\n",
    "\n",
    "print(f'Intercept: {str(BestModel.interceptVector)}')\n",
    "print(f'Coefficients: {BestModel.coefficientMatrix}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "predictions= fitModel.transform(test)\n",
    "accuracy = (\n",
    "    Mc_evaluator.evaluate(\n",
    "        predictions\n",
    "    )\n",
    ")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|               coeff|\n",
      "+--------------------+--------------------+\n",
      "|                  A1|-0.01141507992330...|\n",
      "|                  A2|-0.01028809582257...|\n",
      "|                  A3|-0.01042604851217...|\n",
      "|                  A4|-0.01207538131949...|\n",
      "|                  A5|-0.00996856700474...|\n",
      "|                  A6|-0.01165182450976...|\n",
      "|                  A7|-0.01096699813330...|\n",
      "|                  A8|-0.00991785346613...|\n",
      "|                  A9| -0.0111894425269281|\n",
      "|                 A10|-0.01121952828675...|\n",
      "|            Age_Mons|-0.00199481656435...|\n",
      "|      Qchat-10-Score|-0.03029070189907398|\n",
      "|                 Sex|-2.69163921490370...|\n",
      "|           Ethnicity|-0.00278131811105...|\n",
      "|            Jaundice|-5.71392924310833...|\n",
      "| Family_mem_with_ASD|-2.80229083710591...|\n",
      "|Who completed the...|-0.00382371968582...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coeff_array = BestModel.coefficientMatrix.toArray()\n",
    "coeff_scores = [float(x) for x in coeff_array[0]]\n",
    "result = spark.createDataFrame(\n",
    "    zip(input_columns, coeff_scores),\n",
    "    schema=['features', 'coeff']\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = BestModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|             label|        prediction|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               734|               734|\n",
      "|   mean|0.3215258855585831|0.3215258855585831|\n",
      "| stddev|0.4673805718253027|0.4673805718253027|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|               1.0|               1.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingSummary.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "objectiveHistory:(scaled loss + regularization at each iteration)\n",
      "0.6280142815513996\n",
      "0.5213192624846951\n",
      "0.45856304664143005\n",
      "0.29273569949704176\n",
      "0.2659202876809173\n",
      "0.22708745847954648\n",
      "0.20552710550258288\n",
      "0.18127594989350054\n",
      "0.14398359590390153\n",
      "0.08198058700315335\n",
      "0.07901012687927496\n",
      "0.028392641840305932\n",
      "0.019523105695930434\n",
      "0.012540337225207676\n",
      "0.007486365235160843\n",
      "0.005424466566574381\n",
      "0.002641455221904271\n",
      "0.0017099239720956847\n",
      "0.001008991458378112\n",
      "0.000585111430970679\n",
      "0.00029716417847435773\n"
     ]
    }
   ],
   "source": [
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\" \")\n",
    "print(\"objectiveHistory:(scaled loss + regularization at each iteration)\")\n",
    "[print(objective) for objective in objectiveHistory];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 0.0\n",
      "label 1: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, rate in enumerate(\n",
    "    trainingSummary.falsePositiveRateByLabel):\n",
    "    print(f'label {i}: {rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 1.0\n",
      "label 1: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i, rate in enumerate(\n",
    "    trainingSummary.truePositiveRateByLabel):\n",
    "    print(f'label {i}: {rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Precision by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "F-measure by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      " \n",
      "Accuracy: 1.0\n",
      "FPR: 0.0\n",
      "TPR: 1.0\n",
      "F-measure: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\" \")\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\" \")\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "# Generate confusion matrix and print (includes accuracy)\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\" \")\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\\\n",
    "    .addGrid(\n",
    "        classifier.maxDepth,\n",
    "        [2, 5, 10 ]\n",
    "    )\\\n",
    "    .addGrid(\n",
    "        classifier.numTrees,\n",
    "        [5, 20, 50])\\\n",
    "    .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(\n",
    "    estimator=classifier,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=MulticlassClassificationEvaluator(),\n",
    "    numFolds=5\n",
    ")\n",
    "fitModel = crossval.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances: [0.12332297 0.0829292  0.         0.072007   0.         0.\n",
      " 0.06306404 0.         0.07667703 0.         0.         0.58199976\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BestModel = fitModel.bestModel\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "\n",
    "print(f'Feature Importances: {featureImportances}')\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (\n",
    "    Mc_evaluator.evaluate(\n",
    "        predictions\n",
    "    )\n",
    ")\n",
    "print(f'Accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = [str(i) for i in featureImportances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_df = spark.createDataFrame(\n",
    "    zip(fi, input_columns),\n",
    "    schema=['feature importance', 'Column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "| feature importance|              Column|\n",
      "+-------------------+--------------------+\n",
      "|0.12332297371381817|                  A1|\n",
      "|0.08292920353430017|                  A2|\n",
      "|                0.0|                  A3|\n",
      "|0.07200700252508971|                  A4|\n",
      "|                0.0|                  A5|\n",
      "|                0.0|                  A6|\n",
      "|0.06306403730343825|                  A7|\n",
      "|                0.0|                  A8|\n",
      "|0.07667702628618182|                  A9|\n",
      "|                0.0|                 A10|\n",
      "|                0.0|            Age_Mons|\n",
      "| 0.5819997566371719|      Qchat-10-Score|\n",
      "|                0.0|                 Sex|\n",
      "|                0.0|           Ethnicity|\n",
      "|                0.0|            Jaundice|\n",
      "|                0.0| Family_mem_with_ASD|\n",
      "|                0.0|Who completed the...|\n",
      "+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fi_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = final_data.select(\n",
    "    countDistinct('label')\n",
    ").collect()\n",
    "label_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more than 2 class can not be done\n",
    "# at the moment at pyspark for \n",
    "# Gradient boosting\n",
    "\n",
    "\n",
    "classifier = GBTClassifier()\n",
    "\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\\\n",
    "    .addGrid(\n",
    "        classifier.maxDepth,\n",
    "        [2, 5, 10, 20])\n",
    "    .addGrid(\n",
    "        classifier.maxBins,\n",
    "        [10, 20, 40, 80, 100]\n",
    "    ).GridBuilder()\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1123dae94279c660cf34f777dea29eda36172fe1a19971838176cb40ac3ccca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('spark_env_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
